{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "import scipy.misc\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37minstance-gpu\u001b[m  Mon Feb 11 16:12:23 2019\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   82\u001b[m / \u001b[33m16280\u001b[m MB | \u001b[1m\u001b[30mroot\u001b[m(\u001b[33m82M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45406\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./dataset2/data.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg 0.000000\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 ./dataset2/data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer_df = pd.read_csv('./dataset2/data.txt', sep=' ',\n",
    "                       names=['image_file', 'steer_degree'], \n",
    "                       engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer_df['image_file'] = './dataset2/' + steer_df.image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45406, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>steer_degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset2/0.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset2/1.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset2/2.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset2/3.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset2/4.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_file  steer_degree\n",
       "0  ./dataset2/0.jpg           0.0\n",
       "1  ./dataset2/1.jpg           0.0\n",
       "2  ./dataset2/2.jpg           0.0\n",
       "3  ./dataset2/3.jpg           0.0\n",
       "4  ./dataset2/4.jpg           0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert degrees to Radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer_df['steer_rad'] = steer_df.steer_degree * 0.01745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.       ,  0.204165 ,  0.1813055, ..., -1.4781895, -1.372617 ,\n",
       "       -0.883319 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steer_df.steer_rad.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45406, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = steer_df.iloc[0:31785, :]  # More than 31785 for epoch calculations\n",
    "test = steer_df.iloc[31785:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31785, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13621, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert image into feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _convert_image(image_path, strip, resize, normalize):\n",
    "#     img_matrix = imageio.imread(image_path)\n",
    "#     if strip is not None:\n",
    "#         img_matrix = img_matrix[-strip:]\n",
    "#     if resize is not None:\n",
    "#         img_matrix = scipy.misc.imresize(img_matrix, resize)\n",
    "#     if not normalize:\n",
    "#         return img_matrix\n",
    "#     return img_matrix / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batch_pointer = 0\n",
    "# test_batch_pointer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_batch_data(size, subset='train', **kwargs):\n",
    "#     global train_batch_pointer\n",
    "#     global test_batch_pointer\n",
    "#     strip = kwargs.get('strip')\n",
    "#     resize = kwargs.get('resize')\n",
    "#     normalize = kwargs.get('normalize', True)\n",
    "# #     train_pointer = kwargs.get('train_pointer', -1)\n",
    "# #     test_pointer = kwargs.get('test_pointer', -1)\n",
    "    \n",
    "#     fetcher = kwargs.get('fetcher', 'sequential')\n",
    "#     if fetcher not in ['sequential', 'randomized']:\n",
    "#         raise NotImplementedError('Fetcher type is not implemented')\n",
    "    \n",
    "#     x = []\n",
    "    \n",
    "#     if subset == 'train':\n",
    "#         if fetcher == 'randomized':\n",
    "#             train_index = np.random.randint(low=0, high=train.shape[0], size=size)\n",
    "#         else:\n",
    "# #             if train_batch_pointer == - 1 or train_batch_pointer > train.shape[0]:\n",
    "# #                 raise IndexError('Train pointer value is less/more than it should be')\n",
    "#             train_index = np.arange(train_batch_pointer, train_batch_pointer + size)\n",
    "# #         print(train_pointer, train_pointer+size)\n",
    "#         images = train.image_file.values[train_index]\n",
    "#         y = train.steer_rad.values[train_index]\n",
    "#         train_batch_pointer += size\n",
    "\n",
    "#     elif subset == 'test':\n",
    "#         if fetcher == 'randomized':\n",
    "#             train_index = np.random.randint(low=0, high=test.shape[0], size=size)\n",
    "#         else:\n",
    "# #             if test_batch_pointer == -1 or test_batch_pointer > test.shape[0]:\n",
    "# #                 raise IndexError('Test pointer value is less/more than it should be')\n",
    "#             test_index = np.arange(test_batch_pointer, test_batch_pointer + size)\n",
    "#         images = test.image_file.values[test_index]\n",
    "#         y = test.steer_rad.values[test_index]\n",
    "#         test_batch_pointer += size\n",
    "#     for image in images:\n",
    "#         x.append(_convert_image(image, strip, resize, normalize))\n",
    "    \n",
    "#     return np.array(x), y.reshape(-1, 1)\n",
    "import random\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "#read data.txt\n",
    "with open(\"./dataset2/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"./dataset2/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "#shuffle list of images\n",
    "c = list(zip(xs, ys))\n",
    "random.shuffle(c)\n",
    "xs, ys = zip(*c)\n",
    "\n",
    "train_xs = xs[:int(len(xs) * 0.8)]\n",
    "train_ys = ys[:int(len(xs) * 0.8)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.2):]\n",
    "val_ys = ys[-int(len(xs) * 0.2):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(\n",
    "            scipy.misc.imread(train_xs[(\n",
    "                train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(\n",
    "            scipy.misc.imread(\n",
    "                val_xs[(val_batch_pointer + i) % num_val_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Conv Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(shape, name, init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Get weights and initialize them\n",
    "    for the each layer.\n",
    "    \"\"\"\n",
    "    if init == 'glorot_uniform':\n",
    "        i = tf.glorot_uniform_initializer(seed=42)\n",
    "    elif init == 'glorot_normal':\n",
    "        i = tf.glorot_normal_initializer(seed=42)\n",
    "    elif init == 'xavier_uniform':\n",
    "        i = tf.contrib.layers.xavier_initializer(seed=42)\n",
    "    elif init == 'xavier_normal':\n",
    "        i = tf.contrib.layers.xavier_initializer(seed=42, uniform=False)\n",
    "    elif init == 'he_uniform':\n",
    "        i = tf.keras.initializers.he_uniform(seed=42)\n",
    "    elif init == 'he_normal':\n",
    "        i = tf.keras.initializers.he_normal(seed=42)\n",
    "    elif init == 'raw':\n",
    "        if len(shape) > 1:\n",
    "            initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "            return tf.Variable(initial)\n",
    "        else:\n",
    "            initial = tf.constant(0.1, shape=shape)\n",
    "            return tf.Variable(initial)\n",
    "#         i = tf.initializers.random_normal(seed=42)\n",
    "\n",
    "    return tf.get_variable(\n",
    "        name=name,\n",
    "        shape=shape,\n",
    "        dtype=tf.float32,\n",
    "        initializer=i,)\n",
    "\n",
    "def flatten(X, size):\n",
    "    return tf.reshape(X, [-1, size])\n",
    "    \n",
    "\n",
    "def Dense(X, size, init, name, activation):\n",
    "    w = get_weights(shape=size, name='W_' + name, init=init)\n",
    "    b = get_weights(shape=[size[-1]], name='b_' + name, init=init)\n",
    "    \n",
    "    dense = tf.matmul(X, w) + b\n",
    "    print(name, size, size[-1])\n",
    "    ## Applying activation\n",
    "\n",
    "    if activation == 'relu':\n",
    "        h_fc = tf.nn.relu(dense)\n",
    "    elif activation == 'sigmoid':\n",
    "        h_fc = tf.nn.sigmoid(dense)\n",
    "    elif activation == 'leaky_relu':\n",
    "        h_fc = tf.nn.leaky_relu(dense)\n",
    "    elif activation == 'tanh':\n",
    "        h_fc = tf.nn.tanh(dense)\n",
    "    elif activation == 'atan':\n",
    "        h_fc = tf.atan(dense)\n",
    "    \n",
    "#     if dropout >= 0.0 and dropout < 1.0:\n",
    "#         return tf.nn.dropout(h_fc, keep_prob=dropout)\n",
    "    return h_fc\n",
    "\n",
    "def Conv2d(X, size, stride, init, name, padding, activation):\n",
    "    \"\"\"\n",
    "    Get a conv layer on X for weight W and bias b\n",
    "    with stride and padding\n",
    "    \"\"\"\n",
    "    print(name, size, size[-1])\n",
    "    w = get_weights(shape=size, name='W_' + name, init=init)\n",
    "    b = get_weights(shape=[size[-1]], name='b_' + name, init=init)\n",
    "    \n",
    "    conv = tf.nn.conv2d(X, w, strides=[1, stride, stride, 1], \n",
    "                        padding=padding) + b\n",
    "    \n",
    "    ## Applying activation\n",
    "\n",
    "    if activation == 'relu':\n",
    "        h_conv = tf.nn.relu(conv)\n",
    "    elif activation == 'sigmoid':\n",
    "        h_conv = tf.nn.sigmoid(conv)\n",
    "    elif activation == 'leaky_relu':\n",
    "        h_conv = tf.nn.leaky_relu(conv)\n",
    "    \n",
    "    return h_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_weights((5, 5, 3, 24), name='conv2d_1').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_weights((24), name='bias_conv2d_1').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # Reset any existing computation graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(name='input', dtype=tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(name='output', dtype=tf.float32, shape=[None, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1 (5, 5, 3, 24) 24\n",
      "conv2d_2 (5, 5, 24, 36) 36\n",
      "conv2d_3 (5, 5, 36, 48) 48\n",
      "conv2d_4 (3, 3, 48, 64) 64\n",
      "conv2d_5 (3, 3, 64, 64) 64\n",
      "dense1 (1152, 1164) 1164\n",
      "dense2 (1164, 100) 100\n",
      "dense3 (100, 50) 50\n",
      "dense4 (50, 10) 10\n",
      "output (10, 1) 1\n"
     ]
    }
   ],
   "source": [
    "# first convolutional layer\n",
    "h_conv1 = Conv2d(x_image, (5, 5, 3, 24), 2, \n",
    "                 init='raw', name='conv2d_1',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# second convolutional layer\n",
    "h_conv2 = Conv2d(h_conv1, (5, 5, 24, 36), 2, \n",
    "                 init='raw', name='conv2d_2',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# third convolutional layer\n",
    "h_conv3 = Conv2d(h_conv2, (5, 5, 36, 48), 2, \n",
    "                 init='raw', name='conv2d_3',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# fourth convolutional layer\n",
    "h_conv4 = Conv2d(h_conv3, (3, 3, 48, 64), 1, \n",
    "                 init='raw', name='conv2d_4',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# fifth convolutional layer\n",
    "h_conv5 = Conv2d(h_conv4, (3, 3, 64, 64), 1, \n",
    "                 init='raw', name='conv2d_5',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# Flatten layer\n",
    "h_conv5_flatten = flatten(h_conv5, size=1152)\n",
    "\n",
    "# Dense layer 1\n",
    "h_fc1 = Dense(h_conv5_flatten, (1152, 1164), name='dense1',\n",
    "              init='raw',\n",
    "             activation='relu')\n",
    "# Dropout 1\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Dense Layer 2\n",
    "h_fc2 = Dense(h_fc1_drop, (1164, 100), name='dense2',\n",
    "              init='raw',\n",
    "             activation='relu')\n",
    "# Dropout 2\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "# Dense Layer 3\n",
    "h_fc3 = Dense(h_fc2_drop, (100, 50), name='dense3',\n",
    "              init='raw',\n",
    "             activation='relu')\n",
    "# Dropout 3\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "# Dense Layer 4\n",
    "h_fc4 = Dense(h_fc3_drop, (50, 10), name='dense4',\n",
    "              init='raw',\n",
    "             activation='relu')\n",
    "\n",
    "# Dropout 4\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "# Output\n",
    "Y = Dense(h_fc4_drop, (10, 1), name='output',\n",
    "          init='raw',\n",
    "          activation='atan')\n",
    "y = tf.multiply(Y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = './save/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    L2NormConst = 0.001\n",
    "    train_vars = tf.trainable_variables()\n",
    "    loss = tf.reduce_mean(tf.square(tf.subtract(y_, y))) + tf.add_n(\n",
    "        [tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # create a summary to monitor cost tensor\n",
    "    tf.summary.scalar(name=\"RMSE\", tensor=loss)\n",
    "    # merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "\n",
    "    logs_path = './logs'\n",
    "    summary_writer = tf.summary.FileWriter(logdir=logs_path, graph=tf.get_default_graph())\n",
    "    epochs = 30\n",
    "    batch_size = 100\n",
    "    with tf.device('/gpu:0'):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(int(num_images/batch_size)):\n",
    "                xs, ys = LoadTrainBatch(batch_size)\n",
    "                train_step.run(feed_dict={x: xs, y_: ys, keep_prob: 0.8})\n",
    "                if i % 10 == 0:\n",
    "                    xs, ys = LoadValBatch(batch_size)\n",
    "                    loss_value = loss.eval(feed_dict={x: xs, y_: ys, keep_prob: 1.0})\n",
    "                    print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "                # write logs at every iteration\n",
    "                summary = merged_summary_op.eval(feed_dict={x:xs, y_: ys, keep_prob: 1.0})\n",
    "                summary_writer.add_summary(summary, epoch * num_images/batch_size + i)\n",
    "\n",
    "                if i % batch_size == 0:\n",
    "                    if not os.path.exists(LOGDIR):\n",
    "                        os.makedirs(LOGDIR)\n",
    "                    checkpoint_path = os.path.join(LOGDIR, \"model.ckpt\")\n",
    "                    filename = saver.save(sess, checkpoint_path)\n",
    "            print(\"Model saved in file: %s\" % filename)\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "              \"--> tensorboard --logdir=./logs \" \\\n",
    "              \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 5 steps of the last epoch\n",
    "```\n",
    "Epoch: 29, Step: 3310, Loss: 0.146305\n",
    "Epoch: 29, Step: 3320, Loss: 0.137446\n",
    "Epoch: 29, Step: 3330, Loss: 0.132673\n",
    "Epoch: 29, Step: 3340, Loss: 0.130797\n",
    "Epoch: 29, Step: 3350, Loss: 0.443287\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # Reset any existing computation graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(name='input', dtype=tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(name='output', dtype=tf.float32, shape=[None, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1 (5, 5, 3, 24) 24\n",
      "conv2d_2 (5, 5, 24, 36) 36\n",
      "conv2d_3 (5, 5, 36, 48) 48\n",
      "conv2d_4 (3, 3, 48, 64) 64\n",
      "conv2d_5 (3, 3, 64, 64) 64\n",
      "dense1 (1152, 1164) 1164\n",
      "dense2 (1164, 100) 100\n",
      "dense3 (100, 50) 50\n",
      "dense4 (50, 10) 10\n"
     ]
    }
   ],
   "source": [
    "# first convolutional layer\n",
    "h_conv1 = Conv2d(x_image, (5, 5, 3, 24), 2, \n",
    "                 init='raw', name='conv2d_1',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# second convolutional layer\n",
    "h_conv2 = Conv2d(h_conv1, (5, 5, 24, 36), 2, \n",
    "                 init='raw', name='conv2d_2',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# third convolutional layer\n",
    "h_conv3 = Conv2d(h_conv2, (5, 5, 36, 48), 2, \n",
    "                 init='raw', name='conv2d_3',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# fourth convolutional layer\n",
    "h_conv4 = Conv2d(h_conv3, (3, 3, 48, 64), 1, \n",
    "                 init='raw', name='conv2d_4',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# fifth convolutional layer\n",
    "h_conv5 = Conv2d(h_conv4, (3, 3, 64, 64), 1, \n",
    "                 init='raw', name='conv2d_5',\n",
    "                 padding='VALID', activation='relu')\n",
    "\n",
    "# Flatten layer\n",
    "h_conv5_flatten = flatten(h_conv5, size=1152)\n",
    "\n",
    "# Dense layer 1\n",
    "h_fc1 = Dense(h_conv5_flatten, (1152, 1164), name='dense1',\n",
    "              init='raw',\n",
    "             activation='relu')\n",
    "# Dropout 1\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Dense Layer 2\n",
    "h_fc2 = Dense(h_fc1_drop, (1164, 100), name='dense2',\n",
    "              init='raw',\n",
    "             activation='relu')\n",
    "# Dropout 2\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "# Dense Layer 3\n",
    "h_fc3 = Dense(h_fc2_drop, (100, 50), name='dense3',\n",
    "              init='raw',\n",
    "             activation='relu')\n",
    "# Dropout 3\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "# Dense Layer 4\n",
    "h_fc4 = Dense(h_fc3_drop, (50, 10), name='dense4',\n",
    "              init='raw',\n",
    "             activation='relu')\n",
    "\n",
    "# Dropout 4\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "# Output\n",
    "W_fc5 = get_weights([10, 1], name='W_fc5', init='raw')\n",
    "b_fc5 = get_weights([1], name='b_fc5', init='raw')\n",
    "y = tf.matmul(h_fc4_drop, W_fc5) + b_fc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = './save/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    L2NormConst = 0.001\n",
    "    train_vars = tf.trainable_variables()\n",
    "    loss = tf.reduce_mean(tf.square(tf.subtract(y_, y))) + tf.add_n(\n",
    "        [tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "    train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # create a summary to monitor cost tensor\n",
    "    tf.summary.scalar(name=\"RMSE\", tensor=loss)\n",
    "    # merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "\n",
    "    logs_path = './logs'\n",
    "    summary_writer = tf.summary.FileWriter(logdir=logs_path, graph=tf.get_default_graph())\n",
    "    epochs = 30\n",
    "    batch_size = 100\n",
    "    with tf.device('/gpu:0'):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(int(num_images/batch_size)):\n",
    "                xs, ys = LoadTrainBatch(batch_size)\n",
    "                train_step.run(feed_dict={x: xs, y_: ys, keep_prob: 0.5})\n",
    "                if i % 10 == 0:\n",
    "                    xs, ys = LoadValBatch(batch_size)\n",
    "                    loss_value = loss.eval(feed_dict={x: xs, y_: ys, keep_prob: 1.0})\n",
    "                    print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "                # write logs at every iteration\n",
    "                summary = merged_summary_op.eval(feed_dict={x:xs, y_: ys, keep_prob: 1.0})\n",
    "                summary_writer.add_summary(summary, epoch * num_images/batch_size + i)\n",
    "\n",
    "                if i % batch_size == 0:\n",
    "                    if not os.path.exists(LOGDIR):\n",
    "                        os.makedirs(LOGDIR)\n",
    "                    checkpoint_path = os.path.join(LOGDIR, \"model2.ckpt\")\n",
    "                    filename = saver.save(sess, checkpoint_path)\n",
    "            print(\"Model saved in file: %s\" % filename)\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "              \"--> tensorboard --logdir=./logs \" \\\n",
    "              \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 5 steps of last epoch\n",
    "```\n",
    "Epoch: 29, Step: 3310, Loss: 0.0919582\n",
    "Epoch: 29, Step: 3320, Loss: 0.136387\n",
    "Epoch: 29, Step: 3330, Loss: 0.193896\n",
    "Epoch: 29, Step: 3340, Loss: 0.134995\n",
    "Epoch: 29, Step: 3350, Loss: 0.126513\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Output](Result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For video link:** https://youtu.be/zhbPPFHbLDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 50360\r\n",
      "-rw-rw-r-- 1 mayukhpay mayukhpay       79 Feb 11 23:40 checkpoint\r\n",
      "-rw-rw-r-- 1 mayukhpay mayukhpay 31920357 Feb 11 23:40 model2.ckpt\r\n",
      "-rw-rw-r-- 1 mayukhpay mayukhpay   317497 Feb 11 23:40 model2.ckpt.meta\r\n",
      "-rw-rw-r-- 1 mayukhpay mayukhpay 19152108 Feb 11 21:13 model.ckpt\r\n",
      "-rw-rw-r-- 1 mayukhpay mayukhpay   166715 Feb 11 21:13 model.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The initial model works better\n",
    "- The updated model is performing well but not as good as the initial one.\n",
    "- I hardly think not doing `atan` at output was the main reason.\n",
    "- Because now we are directly taking values instead of `atan` and square of it, the loss on paper is better thatn the previous one because I am getting more granular control over the output instead of a smoothed out value.\n",
    "- I guess the lower performacne is due to the `learning rate` and `dropout` rate changes.\n",
    "\n",
    "Below you can see the sample output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
